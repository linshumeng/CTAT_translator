{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "# from bs4 import BeautifulSoup\n",
    "# from tqdm import tqdm\n",
    "# import glob\n",
    "# import json\n",
    "# import translators.server as tss\n",
    "\n",
    "STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create name for variable\n",
    "def clean_name(s, convert_to_lower=True):\n",
    "    s = re.sub('<[^<]+?>', '', s) # markup\n",
    "    s = re.sub('[^0-9a-zA-Z_\\s]', '', s) # keep alnum\n",
    "    s = re.sub('\\t\\n\\r', '', s) # remove tab, line break, carriage return\n",
    "    s = ' '.join(s.split()) # remove redundant whitespace\n",
    "    return s.lower() if convert_to_lower else s\n",
    "\n",
    "# remove unnecessary part in value\n",
    "def clean_phrase(s, convert_to_lower=False):\n",
    "    if(s is None or s == ''):\n",
    "        return None\n",
    "    s = re.sub('\\t\\n\\r', '', s) # remove tab, line break, carriage return\n",
    "    s = ' '.join(s.split()) # remove redundant whitespace\n",
    "    return s.lower() if convert_to_lower else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable\n",
    "def make_var(phrase, signature='_', keep_n_words=4):\n",
    "    if (phrase is None or phrase == ''):\n",
    "        return ''\n",
    "    the_clean_phrase = clean_phrase(phrase) \n",
    "    # print(the_clean_phrase)\n",
    "    if the_clean_phrase in var_phrase_map: # if the variable in var_phrase_map\n",
    "        return var_phrase_map[the_clean_phrase]\n",
    "    else:\n",
    "        h = signature + '_' + '_'.join([word for word in clean_name(phrase).split(' ') if word not in STOPWORDS][:keep_n_words])\n",
    "        v = '%(' + str(h) + ')%' # create variable name\n",
    "        var_phrase_map[the_clean_phrase] = v # dict key: variable value, dict value: variable name\n",
    "        return v\n",
    "\n",
    "# change variable name\n",
    "def change_var(old_name, signature='_', keep_n_words=4):\n",
    "    if old_name in var_name_map:\n",
    "        return var_name_map[old_name]\n",
    "    else:\n",
    "        phrase = table_new.loc[old_name].iloc[0] # find the pharse in the mass production table\n",
    "        if (old_name is None or old_name == '' or pd.isnull(phrase)):\n",
    "            return ''\n",
    "        the_clean_phrase = clean_phrase(phrase) \n",
    "        h = signature + '_' + '_'.join([word for word in clean_name(phrase).split(' ') if word not in STOPWORDS][:keep_n_words])\n",
    "        v = '%(' + str(h) + ')%'\n",
    "        var_name_map[old_name] = v\n",
    "        table_new.rename(index={old_name:v}, inplace=True) # dict key: variable value, dict value: variable name\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find hash\n",
    "def find_hash(s):\n",
    "    if(s is None or s == ''):\n",
    "        return False\n",
    "    # replace \"%(\" and \"%)\" to detect whether the variable name is a hash-like\n",
    "    s = re.sub('%\\(', '', s) # \"\\\" is for re\n",
    "    s = re.sub('\\)%', '', s)\n",
    "    return s.lstrip('-').isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pharse with variable\n",
    "def iterate_generic(tag: str, root):\n",
    "    \"\"\"txt should be %% type or a pharse.\"\"\"\n",
    "    table_new_index_list = table_new.index.tolist() \n",
    "    count = 1\n",
    "    for element in root.iter(tag):\n",
    "        if tag == 'Input' and element[0].tag == 'value': # find input value\n",
    "            txt = element[0].text\n",
    "        else:\n",
    "            txt = element.text\n",
    "        # if txt is empty\n",
    "        if clean_phrase(txt) is None or clean_phrase(txt) == '':\n",
    "            continue\n",
    "        # elif txt is already in the mass production table and it is not a hash-like\n",
    "        elif txt in table_new_index_list and find_hash(txt) is False:\n",
    "            continue\n",
    "        # elif txt is already in the mass production table and it is a hash-like\n",
    "        elif txt in table_new_index_list and find_hash(txt) is True:\n",
    "            if tag == 'Input':\n",
    "                element[0].text = change_var(txt, signature=tag+'_'+str(count))\n",
    "            else:\n",
    "                element.text = change_var(txt, signature=tag+'_'+str(count))\n",
    "        # else create a variable name for the value\n",
    "        else:\n",
    "            if tag == 'Input':\n",
    "                element[0].text = make_var(txt, signature=tag+'_'+str(count))\n",
    "            else:\n",
    "                element.text = make_var(txt, signature=tag+'_'+str(count))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the tags and call all functions above\n",
    "def process_file(infile_brd, infile_table, outfile_brd, outfile_table):\n",
    "    global tree; tree = ET.parse(infile_brd)\n",
    "    print(\"mass production brd input read\")\n",
    "    print(\"path: \" + infile_brd)\n",
    "    root = tree.getroot()\n",
    "    global var_phrase_map; var_phrase_map = dict()\n",
    "    global var_name_map; var_name_map = dict()\n",
    "\n",
    "    global table_new; table_new = pd.read_csv(infile_table, sep=\"\\t\", index_col=0)\n",
    "    print(\"mass production table input read\")\n",
    "    print(\"path: \" + infile_table)\n",
    "\n",
    "    tags = ['hintMessage', 'buggyMessage', 'successMessage', \n",
    "            'label', 'Input']\n",
    "    for tag in tags:\n",
    "        iterate_generic(tag, root) \n",
    "\n",
    "    # create new dataframe and concat it with the latest mass production table\n",
    "    df_new = pd.DataFrame(var_phrase_map.keys(), index = list(var_phrase_map.values()))\n",
    "    df_dup = pd.concat([df_new.T]*len(table_new.columns)).T\n",
    "    df_dup.columns = table_new.columns\n",
    "    df_mix = pd.concat([table_new, df_dup])\n",
    "    df_mix.index.name = table_new.index.name\n",
    "\n",
    "    # export the csv\n",
    "    df_mix.to_csv(outfile_table, encoding=\"utf-8\", sep=\"\\t\")\n",
    "    print(\"mass production table output finished\")\n",
    "    print(\"path: \" + outfile_table)\n",
    "\n",
    "    # export the brd\n",
    "    tree.write(outfile_brd)\n",
    "    print(\"mass production brd output finished\")\n",
    "    print(\"path: \" + outfile_table)\n",
    "\n",
    "    return table_new, df_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass production brd input read\n",
      "path: ./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalTemplate_new.brd\n",
      "mass production table input read\n",
      "path: ./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new.txt\n",
      "mass production table output finished\n",
      "path: ./Output_cleaned_folder/7-17_finalMassProduction_new_cleaned.txt\n",
      "mass production brd output finished\n",
      "path: ./Output_cleaned_folder/7-17_finalMassProduction_new_cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "# read the latest mass production graph and mass production table\n",
    "infile_brd = \"./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalTemplate_new.brd\"\n",
    "infile_table = \"./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new.txt\"\n",
    "\n",
    "# set the output paths\n",
    "outfile_brd = infile_brd.replace('/HTML_folder/7.17 HTML/7.17 HTML/MassProduction/', '/Output_cleaned_folder/').replace('.brd', '_cleaned.brd')\n",
    "outfile_table = infile_table.replace('/HTML_folder/7.17 HTML/7.17 HTML/MassProduction/', '/Output_cleaned_folder/').replace('.txt', '_cleaned.txt')\n",
    "\n",
    "# run the process function\n",
    "df_1, df_2 = process_file(infile_brd, infile_table, outfile_brd, outfile_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5cbd4e664087b96353283f4ff050485ff797d3250d76f0a980158f1bcc99c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
