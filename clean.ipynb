{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import json\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "# from bs4 import BeautifulSoup\n",
    "# from tqdm import tqdm\n",
    "\n",
    "import translators.server as tss\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create name for variable\n",
    "def clean_name(s, convert_to_lower=True):\n",
    "    s = re.sub('<[^<]+?>', '', s) #markup\n",
    "    s = re.sub('[^0-9a-zA-Z_\\s]', '', s) #keep alnum\n",
    "    s = re.sub('\\t\\n\\r', '', s) #remove tab, line break, carriage return\n",
    "    s = ' '.join(s.split()) #remove redundant whitespace\n",
    "    return s.lower() if convert_to_lower else s\n",
    "\n",
    "# remove unnecessary part in value\n",
    "def clean_phrase(s, convert_to_lower=False):\n",
    "    if(s is None or s == ''):\n",
    "        return None\n",
    "    s = re.sub('\\t\\n\\r', '', s) #remove tab, line break, carriage return\n",
    "    s = ' '.join(s.split()) #remove redundant whitespace\n",
    "    return s.lower() if convert_to_lower else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable\n",
    "def make_var(phrase, signature='_', keep_n_words=4):\n",
    "    if (phrase is None or phrase == ''):\n",
    "        return ''\n",
    "    the_clean_phrase = clean_phrase(phrase) \n",
    "    # print(the_clean_phrase)\n",
    "    if the_clean_phrase in var_phrase_map:\n",
    "        return var_phrase_map[the_clean_phrase]\n",
    "    else:\n",
    "        h = signature + '_' + '_'.join([word for word in clean_name(phrase).split(' ') if word not in STOPWORDS][:keep_n_words])\n",
    "        v = '%(' + str(h) + ')%'\n",
    "        # key: value of the variable, value: value of the variable\n",
    "        var_phrase_map[the_clean_phrase] = v\n",
    "        # print('v', v)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace pharse with variable\n",
    "def iterate_generic(tag: str, root):\n",
    "    \"\"\"txt should be %% type or a pharse.\"\"\"\n",
    "    count = 1\n",
    "    for element in root.iter(tag):\n",
    "        if tag == 'Input' and count > 1:\n",
    "            continue\n",
    "        if tag == 'Input':\n",
    "            txt = element[0].text\n",
    "        else:\n",
    "            txt = element.text\n",
    "        if txt in table_new_index_list or clean_phrase(txt) is None or clean_phrase(txt) == '':\n",
    "            continue\n",
    "        else:\n",
    "            # print(txt)\n",
    "        #     # store_list.append(clean_phrase(txt))\n",
    "            if tag == 'Input':\n",
    "                element[0].text = make_var(txt, signature=tag+'_'+str(count))\n",
    "            else:\n",
    "                # print(txt)\n",
    "                element.text = make_var(txt, signature=tag+'_'+str(count))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the tags and call all functions above\n",
    "def process_file(infile_brd, infile_table, outfile_table, outfile_brd):\n",
    "    global tree; tree = ET.parse(infile_brd)\n",
    "    print(\"mass production brd input read\")\n",
    "    print(\"path: \" + infile_brd)\n",
    "    global root; root = tree.getroot()\n",
    "    global var_phrase_map; var_phrase_map = dict()\n",
    "    global store_dict; store_dict = {}\n",
    "\n",
    "    table_new = pd.read_csv(infile_table, sep=\"\\t\", index_col=0)\n",
    "    print(\"mass production table input read\")\n",
    "    print(\"path: \" + infile_table)\n",
    "    global table_new_index_list; table_new_index_list = table_new.index.tolist() \n",
    "\n",
    "    tags = ['hintMessage', 'buggyMessage', 'successMessage', \n",
    "            'label', 'Input']\n",
    "    for tag in tags:\n",
    "        iterate_generic(tag, root) \n",
    "\n",
    "    # create new dataframe and concat it with the latest mass production table\n",
    "    df_new = pd.DataFrame(var_phrase_map.keys(), index = list(var_phrase_map.values()))\n",
    "    df_dup = pd.concat([df_new.T]*len(table_new.columns)).T\n",
    "    df_dup.columns = table_new.columns\n",
    "    df_mix = pd.concat([table_new, df_dup])\n",
    "\n",
    "    # export the csv\n",
    "    df_mix.to_csv(outfile_table, encoding=\"utf-8\", sep=\"\\t\")\n",
    "    print(\"mass production table output finished\")\n",
    "    print(\"path: \" + outfile_table)\n",
    "\n",
    "    # export the brd\n",
    "    tree.write(outfile_brd)\n",
    "    print(\"mass production brd output finished\")\n",
    "    print(\"path: \" + outfile_table)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass production brd input read\n",
      "path: ./HTML_folder/6.05 HTML/6.05 HTML/MassProduction/6_5.brd\n",
      "mass production table input read\n",
      "path: ./HTML_folder/6.05 HTML/6.05 HTML/MassProduction/6_5.txt\n",
      "mass production table output finished\n",
      "path: ./Output_cleaned_folder/6_5_cleaned.txt\n",
      "mass production brd output finished\n",
      "path: ./Output_cleaned_folder/6_5_cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "# read the latest mass production graph\n",
    "infile_brd = \"./HTML_folder/6.05 HTML/6.05 HTML/MassProduction/6_5.brd\"\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "# read the latest mass production table\n",
    "infile_table = \"./HTML_folder/6.05 HTML/6.05 HTML/MassProduction/6_5.txt\"\n",
    "\n",
    "# set the output paths\n",
    "# outfile_table = './Output_cleaned_folder/6.5_cleaned.txt'\n",
    "# outfile_brd = \"./Output_cleaned_folder/6.5_cleaned.brd\"\n",
    "outfile_brd = infile_brd.replace('/HTML_folder/6.05 HTML/6.05 HTML/MassProduction/', '/Output_cleaned_folder/').replace('.brd', '_cleaned.brd')\n",
    "outfile_table = infile_table.replace('/HTML_folder/6.05 HTML/6.05 HTML/MassProduction/', '/Output_cleaned_folder/').replace('.txt', '_cleaned.txt')\n",
    "\n",
    "# run the process function\n",
    "process_file(infile_brd, infile_table, outfile_table, outfile_brd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5cbd4e664087b96353283f4ff050485ff797d3250d76f0a980158f1bcc99c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
