{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean():\n",
    "    \"\"\"the class for clean purpose\"\"\"\n",
    "    def __init__(self, infile_brd, infile_table, outfile_brd, outfile_table):\n",
    "        self.infile_brd = infile_brd\n",
    "        self.infile_table = infile_table\n",
    "        self.outfile_brd = outfile_brd\n",
    "        self.outfile_table = outfile_table\n",
    "        self.var_phrase_map = dict()\n",
    "        self.var_name_map = dict()\n",
    "        self.table_new = None\n",
    "        self.table_new_index_list = None\n",
    "\n",
    "    def clean_name(self, s, convert_to_lower=True):\n",
    "        \"\"\"create name for variables in .brd\"\"\"\n",
    "        s = re.sub('<[^<]+?>', '', s) # markup\n",
    "        s = re.sub('[^0-9a-zA-Z_\\s]', '', s) # keep alnum\n",
    "        s = re.sub('\\t\\n\\r', '', s) # remove tab, line break, carriage return\n",
    "        s = ' '.join(s.split()) # remove redundant whitespace\n",
    "        return s.lower() if convert_to_lower else s\n",
    "    \n",
    "    def clean_phrase(self, s, convert_to_lower=False):\n",
    "        \"\"\"remove unnecessary part in value\"\"\"\n",
    "        if(s is None or s == ''):\n",
    "            return None\n",
    "        s = re.sub('\\t\\n\\r', '', s) # remove tab, line break, carriage return\n",
    "        s = ' '.join(s.split()) # remove redundant whitespace\n",
    "        return s.lower() if convert_to_lower else s\n",
    "\n",
    "    def find_hash(self, s):\n",
    "        \"\"\"find hash-like variable\"\"\"\n",
    "        if(s is None or s == ''):\n",
    "            return False\n",
    "        # replace \"%(\" and \"%)\" to detect whether the variable is a hash-like\n",
    "        s = re.sub('%\\(', '', s) # \"\\(\" is for re to search \"(\"\n",
    "        s = re.sub('\\)%', '', s)\n",
    "        return s.lstrip('-').isdigit() # ignore \"-\" in the variable \n",
    "    \n",
    "    def change_var(self, old_name, signature='_', keep_n_words=4):\n",
    "        \"\"\"change hash-like variable's name in df\"\"\"\n",
    "        if old_name in self.var_name_map:\n",
    "            return self.var_name_map[old_name]\n",
    "        else:\n",
    "            phrase = self.table_new.loc[old_name].iloc[0] # find the first pharse in the mass production table\n",
    "            if (old_name is None or old_name == '' or pd.isnull(phrase)):\n",
    "                return ''\n",
    "            the_clean_phrase = self.clean_phrase(phrase) \n",
    "            h = signature + '_' + '_'.join([word for word in self.clean_name(the_clean_phrase).split(' ') if word not in STOPWORDS][:keep_n_words])\n",
    "            v = '%(' + str(h) + ')%'\n",
    "            self.var_name_map[old_name] = v\n",
    "            self.table_new.rename(index={old_name:v}, inplace=True) # dict key: variable value, dict value: variable name\n",
    "            return v\n",
    "    \n",
    "    def make_var(self, phrase, signature='_', keep_n_words=4):\n",
    "        \"\"\"create variable-value pair\"\"\"\n",
    "        if (phrase is None or phrase == ''):\n",
    "            return ''\n",
    "        the_clean_phrase = self.clean_phrase(phrase) # clean the value(phrase)\n",
    "        # if the variable in self.var_phrase_map\n",
    "        if the_clean_phrase in self.var_phrase_map: \n",
    "            return self.var_phrase_map[the_clean_phrase]\n",
    "        # else create one\n",
    "        else:\n",
    "            h = signature + '_' + '_'.join([word for word in self.clean_name(the_clean_phrase).split(' ') if word not in STOPWORDS][:keep_n_words])\n",
    "            v = '%(' + str(h) + ')%' # create variable name\n",
    "            self.var_phrase_map[the_clean_phrase] = v # dict key: value, dict value: variable\n",
    "            return v\n",
    "        \n",
    "    def process_txt(self, txt, element, tag, count):\n",
    "        \"\"\"process txt\"\"\"\n",
    "        # if txt is empty\n",
    "        if self.clean_phrase(txt) is None or self.clean_phrase(txt) == '':\n",
    "            return\n",
    "        # elif txt is already in the mass production table and it is not a hash-like\n",
    "        elif txt in self.table_new_index_list and self.find_hash(txt) is False:\n",
    "            return\n",
    "        # elif txt is already in the mass production table and it is a hash-like\n",
    "        elif txt in self.table_new_index_list and self.find_hash(txt) is True:\n",
    "            if tag == 'Input':\n",
    "                element[0].text = self.change_var(txt, signature=tag+'_'+str(count))\n",
    "            else:\n",
    "                element.text = self.change_var(txt, signature=tag+'_'+str(count))\n",
    "            return\n",
    "        # else create a variable name for the value\n",
    "        else:\n",
    "            if tag == 'Input':\n",
    "                element[0].text = self.make_var(txt, signature=tag+'_'+str(count))\n",
    "            else:\n",
    "                element.text = self.make_var(txt, signature=tag+'_'+str(count))\n",
    "            return \n",
    "    \n",
    "    def iterate_generic(self, tag: str, root):\n",
    "        \"\"\"replace pharse with variable,\n",
    "            txt should be %% type or a pharse\"\"\"\n",
    "        count = 1\n",
    "        for element in root.iter(tag):\n",
    "            # print(tag)\n",
    "            if tag == 'Input' and element[0].tag == 'value': # find input value\n",
    "                txt = element[0].text\n",
    "                self.process_txt(txt, element, tag, count)\n",
    "            else:\n",
    "                txt = element.text\n",
    "                self.process_txt(txt, element, tag, count)\n",
    "            count += 1\n",
    "\n",
    "    def process_file(self):\n",
    "        \"\"\"read the tags and call all functions above\"\"\"\n",
    "        tree = ET.parse(self.infile_brd)\n",
    "        print(\"mass production brd input read\")\n",
    "        print(\"path: \" + self.infile_brd)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        self.table_new = pd.read_csv(self.infile_table, sep=\"\\t\", index_col=0, keep_default_na=False)\n",
    "        self.table_new_index_list = self.table_new.index.tolist()\n",
    "        print(\"mass production table input read\")\n",
    "        print(\"path: \" + self.infile_table)\n",
    "\n",
    "        tags = ['hintMessage', 'successMessage', 'buggyMessage', 'label', 'Input']\n",
    "        for tag in tags:\n",
    "            self.iterate_generic(tag, root) \n",
    "\n",
    "        # create new dataframe and concat it with the latest mass production table\n",
    "        df_new = pd.DataFrame(self.var_phrase_map.keys(), index = list(self.var_phrase_map.values()))\n",
    "        df_dup = pd.concat([df_new.T]*len(self.table_new.columns)).T\n",
    "        df_dup.columns = self.table_new.columns\n",
    "        df_mix = pd.concat([self.table_new, df_dup])\n",
    "        df_mix.index.name = self.table_new.index.name\n",
    "\n",
    "        # export the csv\n",
    "        df_mix.to_csv(self.outfile_table, encoding=\"utf-8\", sep=\"\\t\")\n",
    "        print(\"mass production table output finished\")\n",
    "        print(\"path: \" + self.outfile_table)\n",
    "\n",
    "        # export the brd\n",
    "        tree.write(self.outfile_brd)\n",
    "        print(\"mass production brd output finished\")\n",
    "        print(\"path: \" + self.outfile_table)\n",
    "\n",
    "        return self.table_new, df_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass production brd input read\n",
      "path: ./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalTemplate_new.brd\n",
      "mass production table input read\n",
      "path: ./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new.txt\n",
      "mass production table output finished\n",
      "path: ./Output_cleaned_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new_cleaned.txt\n",
      "mass production brd output finished\n",
      "path: ./Output_cleaned_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new_cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "infile_brd = \"./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalTemplate_new.brd\"\n",
    "infile_table = \"./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new.txt\"\n",
    "outfile_brd = infile_brd.replace('/HTML_folder/7.17 HTML/7.17 HTML/MassProduction/', '/Output_cleaned_folder/7.17 HTML/7.17 HTML/MassProduction/').replace('.brd', '_cleaned.brd')\n",
    "outfile_table = infile_table.replace('/HTML_folder/7.17 HTML/7.17 HTML/MassProduction/', '/Output_cleaned_folder/7.17 HTML/7.17 HTML/MassProduction/').replace('.txt', '_cleaned.txt')\n",
    "\n",
    "# run the process function\n",
    "clean_process = clean(infile_brd, infile_table, outfile_brd, outfile_table)\n",
    "df_1, df_2 = clean_process.process_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5cbd4e664087b96353283f4ff050485ff797d3250d76f0a980158f1bcc99c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
