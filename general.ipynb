{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from xmldiff import main\n",
    "import os\n",
    "\n",
    "STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean():\n",
    "    \"\"\"the class for clean purpose\"\"\"\n",
    "    def __init__(self, infile_brd, infile_table, outfile_brd, outfile_table):\n",
    "        self.infile_brd = infile_brd\n",
    "        self.infile_table = infile_table\n",
    "        self.outfile_brd = outfile_brd\n",
    "        self.outfile_table = outfile_table\n",
    "        self.var_phrase_map = dict()\n",
    "        self.var_name_map = dict()\n",
    "        self.table_new = None\n",
    "        self.table_new_index_list = None\n",
    "\n",
    "    def clean_name(self, s, convert_to_lower=True):\n",
    "        \"\"\"create name for variables in .brd\"\"\"\n",
    "        s = re.sub('<[^<]+?>', '', s) # markup\n",
    "        s = re.sub('[^0-9a-zA-Z_\\s]', '', s) # keep alnum\n",
    "        s = re.sub('\\t\\n\\r', '', s) # remove tab, line break, carriage return\n",
    "        s = ' '.join(s.split()) # remove redundant whitespace\n",
    "        return s.lower() if convert_to_lower else s\n",
    "    \n",
    "    def clean_phrase(self, s, convert_to_lower=False):\n",
    "        \"\"\"remove unnecessary part in value\"\"\"\n",
    "        if(s is None or s == ''):\n",
    "            return None\n",
    "        s = re.sub('\\t\\n\\r', '', s) # remove tab, line break, carriage return\n",
    "        s = ' '.join(s.split()) # remove redundant whitespace\n",
    "        return s.lower() if convert_to_lower else s\n",
    "\n",
    "    def find_hash(self, s):\n",
    "        \"\"\"find hash-like variable\"\"\"\n",
    "        if(s is None or s == ''):\n",
    "            return False\n",
    "        # replace \"%(\" and \"%)\" to detect whether the variable is a hash-like\n",
    "        s = re.sub('%\\(', '', s) # \"\\(\" is for re to search \"(\"\n",
    "        s = re.sub('\\)%', '', s)\n",
    "        return s.lstrip('-').isdigit() # ignore \"-\" in the variable \n",
    "    \n",
    "    def change_var(self, old_name, signature='_', keep_n_words=4):\n",
    "        \"\"\"change hash-like variable's name in df\"\"\"\n",
    "        if old_name in self.var_name_map:\n",
    "            return self.var_name_map[old_name]\n",
    "        else:\n",
    "            phrase = self.table_new.loc[old_name].iloc[0] # find the first pharse in the mass production table\n",
    "            if (old_name is None or old_name == '' or pd.isnull(phrase)):\n",
    "                return ''\n",
    "            the_clean_phrase = self.clean_phrase(phrase) \n",
    "            h = signature + '_' + '_'.join([word for word in self.clean_name(the_clean_phrase).split(' ') if word not in STOPWORDS][:keep_n_words])\n",
    "            v = '%(' + str(h) + ')%'\n",
    "            self.var_name_map[old_name] = v\n",
    "            self.table_new.rename(index={old_name:v}, inplace=True) # dict key: variable value, dict value: variable name\n",
    "            return v\n",
    "    \n",
    "    def make_var(self, phrase, signature='_', keep_n_words=4):\n",
    "        \"\"\"create variable-value pair\"\"\"\n",
    "        if (phrase is None or phrase == ''):\n",
    "            return ''\n",
    "        the_clean_phrase = self.clean_phrase(phrase) # clean the value(phrase)\n",
    "        # if the variable in self.var_phrase_map\n",
    "        if the_clean_phrase in self.var_phrase_map: \n",
    "            return self.var_phrase_map[the_clean_phrase]\n",
    "        # else create one\n",
    "        else:\n",
    "            h = signature + '_' + '_'.join([word for word in self.clean_name(the_clean_phrase).split(' ') if word not in STOPWORDS][:keep_n_words])\n",
    "            v = '%(' + str(h) + ')%' # create variable name\n",
    "            self.var_phrase_map[the_clean_phrase] = v # dict key: value, dict value: variable\n",
    "            return v\n",
    "        \n",
    "    def process_txt(self, txt, element, tag, count):\n",
    "        \"\"\"process txt\"\"\"\n",
    "        # if txt is empty\n",
    "        if self.clean_phrase(txt) is None or self.clean_phrase(txt) == '':\n",
    "            return\n",
    "        # elif txt is already in the mass production table and it is not a hash-like\n",
    "        elif txt in self.table_new_index_list and self.find_hash(txt) is False:\n",
    "            return\n",
    "        # elif txt is already in the mass production table and it is a hash-like\n",
    "        elif txt in self.table_new_index_list and self.find_hash(txt) is True:\n",
    "            if tag == 'Input':\n",
    "                element[0].text = self.change_var(txt, signature=tag+'_'+str(count))\n",
    "            else:\n",
    "                element.text = self.change_var(txt, signature=tag+'_'+str(count))\n",
    "            return\n",
    "        # else create a variable name for the value\n",
    "        else:\n",
    "            if tag == 'Input':\n",
    "                element[0].text = self.make_var(txt, signature=tag+'_'+str(count))\n",
    "            else:\n",
    "                element.text = self.make_var(txt, signature=tag+'_'+str(count))\n",
    "            return \n",
    "    \n",
    "    def iterate_generic(self, tag: str, root):\n",
    "        \"\"\"replace pharse with variable,\n",
    "            txt should be %% type or a pharse\"\"\"\n",
    "        count = 1\n",
    "        for element in root.iter(tag):\n",
    "            # print(tag)\n",
    "            if tag == 'Input' and element[0].tag == 'value': # find input value\n",
    "                txt = element[0].text\n",
    "                self.process_txt(txt, element, tag, count)\n",
    "            else:\n",
    "                txt = element.text\n",
    "                self.process_txt(txt, element, tag, count)\n",
    "            count += 1\n",
    "\n",
    "    def clean_file(self):\n",
    "        \"\"\"read the tags and call all functions above\"\"\"\n",
    "        tree = ET.parse(self.infile_brd)\n",
    "        print(\"mass production brd input read\")\n",
    "        print(\"path: \" + self.infile_brd)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        self.table_new = pd.read_csv(self.infile_table, sep=\"\\t\", index_col=0, keep_default_na=False)\n",
    "        self.table_new_index_list = self.table_new.index.tolist()\n",
    "        print(\"mass production table input read\")\n",
    "        print(\"path: \" + self.infile_table)\n",
    "\n",
    "        tags = ['hintMessage', 'successMessage', 'buggyMessage', 'label', 'Input']\n",
    "        for tag in tags:\n",
    "            self.iterate_generic(tag, root) \n",
    "\n",
    "        # create new dataframe and concat it with the latest mass production table\n",
    "        df_new = pd.DataFrame(self.var_phrase_map.keys(), index = list(self.var_phrase_map.values()))\n",
    "        df_dup = pd.concat([df_new.T]*len(self.table_new.columns)).T\n",
    "        df_dup.columns = self.table_new.columns\n",
    "        df_mix = pd.concat([self.table_new, df_dup])\n",
    "        df_mix.index.name = self.table_new.index.name\n",
    "\n",
    "        # export the csv\n",
    "        df_mix.to_csv(self.outfile_table, encoding=\"utf-8\", sep=\"\\t\")\n",
    "        print(\"mass production table output finished\")\n",
    "        print(\"path: \" + self.outfile_table)\n",
    "\n",
    "        # export the brd\n",
    "        tree.write(self.outfile_brd)\n",
    "        print(\"mass production brd output finished\")\n",
    "        print(\"path: \" + self.outfile_table)\n",
    "\n",
    "        return self.table_new, df_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mass_produce:\n",
    "    \"\"\"the class for mass produce purpose\"\"\"\n",
    "    def __init__(self, infile_brd, infile_table, outfile_folder):\n",
    "        self.infile_brd = infile_brd\n",
    "        self.infile_table = infile_table\n",
    "        self.outfile_folder = outfile_folder\n",
    "\n",
    "    def replace_var(self):\n",
    "        \"\"\"replace variable with value in the latest mass production table\"\"\"\n",
    "        table_clean = pd.read_csv(self.infile_table, sep=\"\\t\", index_col=0, keep_default_na=False)\n",
    "        for column in range(table_clean.shape[1]):\n",
    "            for row in range(table_clean.shape[0]):\n",
    "                content_new = str(table_clean.iloc[row, column])\n",
    "                start_pattern = \"%\\(\"\n",
    "                # count the number of the replacement in one variable(content_new)\n",
    "                count = [match.start() for match in re.finditer(start_pattern, str(content_new))]\n",
    "                for _ in range(len(count)):\n",
    "                    # find the variable\n",
    "                    start_pattern = \"%\\(\"\n",
    "                    start_index = [match.start() for match in re.finditer(start_pattern, str(content_new))]\n",
    "                    end_pattern = \"\\)%\"\n",
    "                    end_index = [match.start() for match in re.finditer(end_pattern, str(content_new))]\n",
    "                    # no need for replacement\n",
    "                    if start_index == []:\n",
    "                        continue\n",
    "                    else:\n",
    "                        variable = content_new[start_index[0]: end_index[0]+2]\n",
    "                        # find the corresponding column name, and then find the value\n",
    "                        column_name = table_clean.columns[column]\n",
    "                        try:\n",
    "                            value = table_clean.loc[variable, column_name] \n",
    "                            # print(variable, value)\n",
    "                            content_new = content_new.replace(variable, value)\n",
    "                            table_clean.iloc[row, column] = content_new\n",
    "                        except:\n",
    "                            print(variable + \" doesn't exist\")\n",
    "        return table_clean\n",
    "    \n",
    "    def mass_produce_file(self):\n",
    "        \"\"\"iterate and mass produce all the brds\"\"\"\n",
    "        table_clean = self.replace_var()\n",
    "        for i in range(len(table_clean.columns)):\n",
    "            column_name = table_clean.columns[i]\n",
    "            fout = self.outfile_folder + str(table_clean.columns[i]) + \".brd\"\n",
    "            count_line = 0\n",
    "            count_text = 0\n",
    "            with open(self.infile_brd, 'r') as infile, open(fout, 'w+') as outfile:\n",
    "                for line in infile:\n",
    "                    line = line.replace('\\r', '')\n",
    "                    line_str = str(line)\n",
    "                    # replace massproduce\n",
    "                    start_pattern_problem_name = \"<ProblemName>\"\n",
    "                    start_index_problem_name = [match.start() for match in re.finditer(start_pattern_problem_name, line_str)]\n",
    "                    end_pattern_problem_name = \"</ProblemName>\"\n",
    "                    end_index_problem_name = [match.start() for match in re.finditer(end_pattern_problem_name, line_str)]\n",
    "                    start_index_problem_name, end_index_problem_name\n",
    "                    try:\n",
    "                        problem_name_old = line_str[start_index_problem_name[0]+13: end_index_problem_name[0]]\n",
    "                        line_str = line_str.replace(problem_name_old, column_name)\n",
    "                    except:\n",
    "                        pass\n",
    "                    # replace text in first node\n",
    "                    if count_text == 0:\n",
    "                        start_pattern_first_node = '<text>'\n",
    "                        start_index_first_node = [match.start() for match in re.finditer(start_pattern_first_node, line_str)]\n",
    "                        end_pattern_first_node = '</text>'\n",
    "                        end_index_first_node = [match.start() for match in re.finditer(end_pattern_first_node, line_str)]\n",
    "                        if start_index_first_node != []:\n",
    "                            count_text += 1\n",
    "                            text_old = line_str[start_index_first_node[0]+6: end_index_first_node[0]]\n",
    "                            line_str = line_str.replace(text_old, column_name)\n",
    "                    # count the number of the replacement in one variable(line_str)\n",
    "                    start_pattern = \"%\\(\"\n",
    "                    count = [match.start() for match in re.finditer(start_pattern, str(line_str))]\n",
    "                    if count == []:\n",
    "                        line_str = line_str\n",
    "                    else:\n",
    "                        for _ in range(len(count)):\n",
    "                            start_pattern = \"%\\(\"\n",
    "                            start_index = [match.start() for match in re.finditer(start_pattern, str(line_str))]\n",
    "                            end_pattern = \"\\)%\"\n",
    "                            end_index = [match.start() for match in re.finditer(end_pattern, str(line_str))]\n",
    "                            if start_index == []:\n",
    "                                line_str = line_str\n",
    "                            else:\n",
    "                                variable = line_str[start_index[0]: end_index[0]+2]\n",
    "                            try:\n",
    "                                value = table_clean.loc[variable, column_name] \n",
    "                                line_str = line_str.replace(variable, value).replace(\"<%\", \"&lt;%\").replace(\"%>\", \"%&gt;\")\n",
    "                            except:\n",
    "                                print(variable + \" doesn't exist\")\n",
    "                    count_line += 1\n",
    "                    outfile.write(line_str)\n",
    "                print(fout.split(\"/\")[-1] + \" finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class validate():\n",
    "    \"\"\"the class for validate purpose\"\"\"\n",
    "    def __init__(self, old_folder, new_folder):\n",
    "        self.old_folder = old_folder\n",
    "        self.new_folder = new_folder\n",
    "\n",
    "    def check(self, old_brd, new_brd):\n",
    "        \"\"\"use ET.parse to validate\"\"\"\n",
    "        old = ET.parse(old_brd)\n",
    "        new = ET.parse(new_brd)\n",
    "        old_text = old.getroot().itertext()\n",
    "        new_text = new.getroot().itertext()\n",
    "        set_old = set(old_text)\n",
    "        set_new = set(new_text)\n",
    "        if set_old == set_new:\n",
    "            res = \"True\"\n",
    "        else:\n",
    "            res = \"False\"\n",
    "        return set_old, set_new, res\n",
    "\n",
    "    def check_xmldiff(self, old_brd, new_brd):\n",
    "        \"\"\"use xmldiff to validate\"\"\"\n",
    "        diff = main.diff_files(old_brd, new_brd)\n",
    "        if len(diff) == 0:\n",
    "            res = \"True\"\n",
    "        else:\n",
    "            res = \"False\"\n",
    "        return diff, res\n",
    "    \n",
    "    def validate_file(self):\n",
    "        fs_brd = glob.glob(self.old_folder + \"*\")\n",
    "        for old_brd in tqdm(fs_brd, position=0, leave=True):\n",
    "            new_brd = self.new_folder + old_brd.split(\"\\\\\", 1)[-1]\n",
    "            if os.path.exists(new_brd):\n",
    "                new_brd = new_brd\n",
    "            elif os.path.exists(new_brd.replace('Problem', '')):\n",
    "                new_brd = new_brd.replace('Problem', '')\n",
    "            elif os.path.exists(new_brd.replace(old_brd.split(\"\\\\\", 1)[-1], \"Problem\"+old_brd.split(\"\\\\\", 1)[-1])):\n",
    "                new_brd = new_brd.replace(old_brd.split(\"\\\\\", 1)[-1], \"Problem\"+old_brd.split(\"\\\\\", 1)[-1])\n",
    "            else:\n",
    "                print(old_brd.split(\"\\\\\", 1)[-1], \" cannot find reference\")\n",
    "                continue\n",
    "            _, _, res_tree = self.check(old_brd, new_brd)\n",
    "            _, res_diff = self.check_xmldiff(old_brd, new_brd)\n",
    "            print(old_brd.split(\"\\\\\", 1)[-1], res_tree, res_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass production brd input read\n",
      "path: ./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalTemplate_new.brd\n",
      "mass production table input read\n",
      "path: ./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new.txt\n",
      "mass production table output finished\n",
      "path: ./Output_cleaned_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new_cleaned.txt\n",
      "mass production brd output finished\n",
      "path: ./Output_cleaned_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new_cleaned.txt\n",
      "clean task ------\n",
      "%(imgNum)% doesn't exist\n",
      "%(imgNum)% doesn't exist\n",
      "%(imgNum)% doesn't exist\n",
      "%(imgNum)% doesn't exist\n",
      "%(imgNum)% doesn't exist\n",
      "%(imgNum)% doesn't exist\n",
      "%(imgNum)% doesn't exist\n",
      "%(imgNum)% doesn't exist\n",
      "1.brd finished\n",
      "2.brd finished\n",
      "3.brd finished\n",
      "4.brd finished\n",
      "5.brd finished\n",
      "6.brd finished\n",
      "7.brd finished\n",
      "8.brd finished\n",
      "mass produce for clean task ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:03,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.brd True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:00<00:02,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.brd True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:01<00:02,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.brd True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:01<00:01,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.brd True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:02<00:01,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.brd True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:02<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.brd True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:03<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.brd True True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:03<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.brd True True\n",
      "validate for clean task ------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# clean 6.05\n",
    "infile_brd_c = \"./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalTemplate_new.brd\"\n",
    "infile_table_c = \"./HTML_folder/7.17 HTML/7.17 HTML/MassProduction/7-17_finalMassProduction_new.txt\"\n",
    "outfile_brd_c = infile_brd_c.replace('/HTML_folder/7.17 HTML/7.17 HTML/MassProduction/', '/Output_cleaned_folder/7.17 HTML/7.17 HTML/MassProduction/').replace('.brd', '_cleaned.brd')\n",
    "outfile_table_c = infile_table_c.replace('/HTML_folder/7.17 HTML/7.17 HTML/MassProduction/', '/Output_cleaned_folder/7.17 HTML/7.17 HTML/MassProduction/').replace('.txt', '_cleaned.txt')\n",
    "\n",
    "# mass produce for cleaned 6.05\n",
    "infile_table_m = \"./Output_cleaned_folder/6.05 HTML/6.05 HTML/MassProduction/6_5_cleaned.txt\"\n",
    "infile_brd_m = \"./Output_cleaned_folder/6.05 HTML/6.05 HTML/MassProduction/6_5_cleaned.brd\"\n",
    "outfile_folder_m = \"./Output_cleaned_folder/6.05 HTML/6.05 HTML/FinalBRDs/\"\n",
    "\n",
    "# validate for cleanded 6.05\n",
    "old_folder = \"./HTML_folder/6.05 HTML/6.05 HTML/FinalBRDs/\"\n",
    "new_folder = \"./Output_translated_folder/6.05 HTML/6.05 HTML/FinalBRDs/\"\n",
    "\n",
    "# run the process function\n",
    "print(\"clean task ------\")\n",
    "clean_res = clean(infile_brd_c, infile_table_c, outfile_brd_c, outfile_table_c)\n",
    "_, _ = clean_res.clean_file()\n",
    "print(\"mass produce for clean task ------\")\n",
    "mass_produce_clean_res = mass_produce(infile_brd_m, infile_table_m, outfile_folder_m)\n",
    "mass_produce_clean_res.mass_produce_file()\n",
    "print(\"validate for clean task ------\")\n",
    "validate_clean_res = validate(old_folder, new_folder)\n",
    "validate_clean_res.validate_file()\n",
    "print(\"translate task ------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CTAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5cbd4e664087b96353283f4ff050485ff797d3250d76f0a980158f1bcc99c02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
